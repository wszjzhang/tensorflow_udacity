{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import skflow\n",
    "import random\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, cross_validation, metrics\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is all about a building and executing graph. This is a very powerful concept, but it is also cumbersome to start with.\n",
    "Looking under the hood of Scikit Flow, we just used three parts:\n",
    "1. TensorFlowTrainer — class that works out all kinks of optimization (builds part of the graph with gradients, does some gradient clipping, and adds an optimizer).\n",
    "2. logistic_regression — function that creates the graph for logistic regression model.\n",
    "3. linear_regression — function that creates the graph for linear regression model.\n",
    "4. DataFeeder — class that samples mini batches of training data into the model (mini batches are needed because training of TensorFlow happens with Stochastic Gradient Descent where random parts of dataset are shown repeatedly to the model).\n",
    "5. TensorFlowLinearClassifier — this is a class that implements Scikit Learn interface using a LogisticRegression model. It creates a model and a trainer, runs trainer with given dataset on fit() call and runs model in evaluation mode on predict() call.\n",
    "6. TensorFlowLinearRegressor — similar to TensorFlowClassifier, but uses LinearRegression as a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer fully connected neural network\n",
    "An idea behind TensorFlow (and many other deep learning frameworks) is to be able to connect differentiable parts of the model together and optimize them given the same cost (or loss) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('tf_examples/data/titanic_train.csv')\n",
    "y, X = data['Survived'], data[['Age', 'SibSp', 'Fare']].fillna(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1, avg. loss: 10.06707\n",
      "Step #51, epoch #8, avg. loss: 0.73915\n",
      "Step #101, epoch #16, avg. loss: 0.62324\n",
      "Step #151, epoch #25, avg. loss: 0.62795\n",
      "Step #201, epoch #33, avg. loss: 0.62312\n",
      "Step #251, epoch #41, avg. loss: 0.62120\n",
      "Step #301, epoch #50, avg. loss: 0.61702\n",
      "Step #351, epoch #58, avg. loss: 0.61531\n",
      "Step #401, epoch #66, avg. loss: 0.61496\n",
      "Step #451, epoch #75, avg. loss: 0.61467\n",
      "Accuracy: 0.653631\n"
     ]
    }
   ],
   "source": [
    "classifier = skflow.TensorFlowDNNClassifier(\n",
    "...     hidden_units=[10, 20, 10], \n",
    "...     n_classes=2, \n",
    "...     batch_size=128, \n",
    "...     steps=500, \n",
    "...     learning_rate=0.05)\n",
    ">>> classifier.fit(X_train, y_train)\n",
    ">>> score = accuracy_score(classifier.predict(X_test), y_test)\n",
    ">>> print(\"Accuracy: %f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer with tanh activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1, avg. loss: 0.68093\n",
      "Step #51, epoch #8, avg. loss: 0.64784\n",
      "Step #101, epoch #16, avg. loss: 0.63315\n",
      "Step #151, epoch #25, avg. loss: 0.63321\n",
      "Step #201, epoch #33, avg. loss: 0.62441\n",
      "Step #251, epoch #41, avg. loss: 0.61640\n",
      "Step #301, epoch #50, avg. loss: 0.61379\n",
      "Step #351, epoch #58, avg. loss: 0.61022\n",
      "Step #401, epoch #66, avg. loss: 0.61547\n",
      "Step #451, epoch #75, avg. loss: 0.61014\n",
      "Accuracy: 0.692737\n"
     ]
    }
   ],
   "source": [
    ">>> def dnn_tanh(X, y):\n",
    "...    layers = skflow.ops.dnn(X, [10, 20, 10], tf.tanh)\n",
    "...    return skflow.models.logistic_regression(layers, y)\n",
    "\n",
    ">>> classifier = skflow.TensorFlowEstimator(\n",
    "...     model_fn=dnn_tanh, \n",
    "...     n_classes=2,\n",
    "...     batch_size=128,\n",
    "...     steps=500,\n",
    "...     learning_rate=0.05)\n",
    ">>> classifier.fit(X_train, y_train)\n",
    ">>> score = accuracy_score(classifier.predict(X_test), y_test)\n",
    ">>> print(\"Accuracy: %f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, creating a custom model is as easy as writing a function, that takes X and y inputs (which are Tensors) and returns two tensors: predictions and loss. This is where you can start learning TensorFlow APIs to create parts of sub-graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1, avg. loss: 14.36785\n",
      "Step #51, epoch #4, avg. loss: 4.01558\n",
      "Step #101, epoch #8, avg. loss: 2.37071\n",
      "Step #151, epoch #12, avg. loss: 1.73825\n",
      "Step #201, epoch #16, avg. loss: 1.38814\n",
      "Step #251, epoch #20, avg. loss: 1.23454\n",
      "Step #301, epoch #25, avg. loss: 1.12860\n",
      "Step #351, epoch #29, avg. loss: 1.03399\n",
      "Step #401, epoch #33, avg. loss: 0.96408\n",
      "Step #451, epoch #37, avg. loss: 0.89280\n",
      "Accuracy: 0.652778\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "X = digits.images\n",
    "y = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y,\n",
    "    test_size=0.2, random_state=42)\n",
    "\n",
    "# TensorFlow model using Scikit Flow ops\n",
    "\n",
    "def conv_model(X, y):\n",
    "    X = tf.expand_dims(X, 3)\n",
    "    features = tf.reduce_max(skflow.ops.conv2d(X, 12, [3, 3]), [1, 2])\n",
    "    features = tf.reshape(features, [-1, 12])\n",
    "    return skflow.models.logistic_regression(features, y)\n",
    "\n",
    "# Create a classifier, train and predict.\n",
    "classifier = skflow.TensorFlowEstimator(model_fn=conv_model, n_classes=10,\n",
    "                                        steps=500, learning_rate=0.05,\n",
    "                                        batch_size=128)\n",
    "classifier.fit(X_train, y_train)\n",
    "score = metrics.accuracy_score(classifier.predict(X_test), y_test)\n",
    "print('Accuracy: %f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Embarked has next classes: ', array(['S', 'C', 'Q', nan], dtype=object))\n",
      "Step #1, avg. loss: 0.76733\n",
      "Step #21, avg. loss: 0.67197\n",
      "Step #41, epoch #1, avg. loss: 0.67355\n",
      "Step #61, epoch #2, avg. loss: 0.65313\n",
      "Step #81, epoch #3, avg. loss: 0.65903\n",
      "Step #101, epoch #4, avg. loss: 0.65579\n",
      "Step #121, epoch #5, avg. loss: 0.64565\n",
      "Step #141, epoch #6, avg. loss: 0.65923\n",
      "Step #161, epoch #7, avg. loss: 0.65823\n",
      "Step #181, epoch #7, avg. loss: 0.65129\n",
      "Accuracy: 0.625698324022\n",
      "ROC: 0.610550615595\n",
      "Step #1, avg. loss: 0.82722\n",
      "Step #101, epoch #4, avg. loss: 0.82588\n",
      "Step #201, epoch #8, avg. loss: 0.68599\n",
      "Step #301, epoch #13, avg. loss: 0.66034\n",
      "Step #401, epoch #17, avg. loss: 0.65153\n",
      "Step #501, epoch #21, avg. loss: 0.65113\n",
      "Step #601, epoch #26, avg. loss: 0.65095\n",
      "Step #701, epoch #30, avg. loss: 0.65017\n",
      "Step #801, epoch #34, avg. loss: 0.65184\n",
      "Step #901, epoch #39, avg. loss: 0.64966\n",
      "Accuracy: 0.625698324022\n",
      "ROC: 0.610550615595\n"
     ]
    }
   ],
   "source": [
    "X = data[[\"Embarked\"]]\n",
    "y = data[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "embarked_classes = X_train[\"Embarked\"].unique()\n",
    "print('Embarked has next classes: ', embarked_classes)\n",
    "\n",
    "cat_processor = skflow.preprocessing.CategoricalProcessor()\n",
    "X_train = np.array(list(cat_processor.fit_transform(X_train)))\n",
    "X_test = np.array(list(cat_processor.transform(X_test)))\n",
    "\n",
    "# Total number of classes for this variable from Categorical Processor.\n",
    "# Includes unknown token and unique classes for variable.\n",
    "n_classes = len(cat_processor.vocabularies_[0])\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "EMBEDDING_SIZE = 3\n",
    "\n",
    "def categorical_model(X, y):\n",
    "    features = skflow.ops.categorical_variable(\n",
    "        X, n_classes, embedding_size=EMBEDDING_SIZE, name='embarked')\n",
    "    return skflow.models.logistic_regression(tf.squeeze(features, [1]), y)\n",
    "\n",
    "classifier = skflow.TensorFlowEstimator(model_fn=categorical_model,\n",
    "    n_classes=2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: {0}\".format(metrics.accuracy_score(classifier.predict(X_test), y_test)))\n",
    "print(\"ROC: {0}\".format(metrics.roc_auc_score(classifier.predict(X_test), y_test)))\n",
    "\n",
    "### One Hot\n",
    "\n",
    "def one_hot_categorical_model(X, y):\n",
    "    features = skflow.ops.one_hot_matrix(X, n_classes)\n",
    "    return skflow.models.logistic_regression(tf.squeeze(features, [1]), y)\n",
    "\n",
    "classifier = skflow.TensorFlowEstimator(model_fn=one_hot_categorical_model,\n",
    "    n_classes=2, steps=1000, learning_rate=0.01)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: {0}\".format(metrics.accuracy_score(classifier.predict(X_test), y_test)))\n",
    "print(\"ROC: {0}\".format(metrics.roc_auc_score(classifier.predict(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
